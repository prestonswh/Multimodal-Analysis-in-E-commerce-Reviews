{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/swh/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized Histogram Similarity: 1.0\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import requests\n",
    "\n",
    "def load_image_from_url(url):\n",
    "    resp = requests.get(url)\n",
    "    image = np.asarray(bytearray(resp.content), dtype=\"uint8\")\n",
    "    image = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
    "    return image\n",
    "\n",
    "def compute_normalized_histogram(image, bins=256):\n",
    "    hist = []\n",
    "    for i in range(3):  # For each color channel\n",
    "        channel_hist = cv2.calcHist([image], [i], None, [bins], [0, 256])\n",
    "        cv2.normalize(channel_hist, channel_hist, norm_type=cv2.NORM_L2)\n",
    "        hist.append(channel_hist)\n",
    "    return hist\n",
    "\n",
    "def compare_histograms(hist1, hist2, method=cv2.HISTCMP_CORREL):\n",
    "    # Sum of correlations across all channels\n",
    "    similarity = sum(cv2.compareHist(hist1[i], hist2[i], method) for i in range(3)) / 3  # Averaging to keep it within 0-1\n",
    "    return similarity\n",
    "\n",
    "# Load images\n",
    "url_cgi = \"https://m.media-amazon.com/images/I/71FC3tE1mhL._AC_UL1500_.jpg\"\n",
    "url_fgi = \"https://m.media-amazon.com/images/I/71FC3tE1mhL._AC_UL1500_.jpg\"\n",
    "image_cgi = load_image_from_url(url_cgi)\n",
    "image_fgi = load_image_from_url(url_fgi)\n",
    "\n",
    "# Compute histograms\n",
    "hist_cgi = compute_normalized_histogram(image_cgi)\n",
    "hist_fgi = compute_normalized_histogram(image_fgi)\n",
    "\n",
    "# Compare histograms\n",
    "similarity = compare_histograms(hist_cgi, hist_fgi)\n",
    "print(f\"Normalized Histogram Similarity: {similarity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Color Similarities: 100%|██████████| 9484/9484 [00:29<00:00, 318.08it/s]\n",
      "/var/folders/vz/_y_gw0w915v4z_x6ps3fjwwm0000gn/T/ipykernel_27492/1547458846.py:70: InvalidColumnName: \n",
      "Not all pandas column names were valid Stata variable names.\n",
      "The following replacements have been made:\n",
      "\n",
      "    Unnamed: 0   ->   Unnamed__0\n",
      "\n",
      "If this is not what you expect, please make sure you have Stata-compliant\n",
      "column names in your DataFrame (strings only, max 32 characters, only\n",
      "alphanumerics and underscores, no Stata reserved words)\n",
      "\n",
      "  df.drop(columns=columns_to_drop, errors='ignore').to_stata('df_review_color.dta', write_index=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete DataFrame saved to 'df_review_color.csv'.\n",
      "Modified DataFrame saved to 'df_review_color.dta' without specified columns.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import cv2\n",
    "import numpy as np\n",
    "import requests\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "def load_image_from_url(url):\n",
    "    if not url:\n",
    "        return None\n",
    "    try:\n",
    "        resp = requests.get(url)\n",
    "        image = np.asarray(bytearray(resp.content), dtype=\"uint8\")\n",
    "        image = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
    "        return image\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Error loading image from {url}: {e}\")\n",
    "        return None\n",
    "\n",
    "def compute_normalized_histogram(image, bins=256):\n",
    "    if image is None:\n",
    "        return None\n",
    "    hist = []\n",
    "    for i in range(3):  # For each color channel\n",
    "        channel_hist = cv2.calcHist([image], [i], None, [bins], [0, 256])\n",
    "        cv2.normalize(channel_hist, channel_hist, norm_type=cv2.NORM_L2)\n",
    "        hist.append(channel_hist)\n",
    "    return hist\n",
    "\n",
    "def compare_histograms(hist1, hist2, method=cv2.HISTCMP_CORREL):\n",
    "    if hist1 is None or hist2 is None:\n",
    "        return None  # Return None if any histogram is missing\n",
    "    similarity = sum(cv2.compareHist(hist1[i], hist2[i], method) for i in range(3)) / 3\n",
    "    return similarity\n",
    "\n",
    "def extract_first_image_url(image_list_str):\n",
    "    if not image_list_str or image_list_str == '[]':\n",
    "        return None\n",
    "    try:\n",
    "        image_list = json.loads(image_list_str.replace(\"'\", '\"'))\n",
    "        if image_list:\n",
    "            return image_list[0]\n",
    "        else:\n",
    "            return None\n",
    "    except json.JSONDecodeError:\n",
    "        return None\n",
    "\n",
    "def calculate_similarity(row):\n",
    "    if row['cgi_image_url'] is None or row['fgi_image_url'] is None:\n",
    "        return None  # Skip calculation if any URL is missing\n",
    "    image_cgi = load_image_from_url(row['cgi_image_url'])\n",
    "    image_fgi = load_image_from_url(row['fgi_image_url'])\n",
    "    hist_cgi = compute_normalized_histogram(image_cgi)\n",
    "    hist_fgi = compute_normalized_histogram(image_fgi)\n",
    "    return compare_histograms(hist_cgi, hist_fgi)\n",
    "\n",
    "def main():\n",
    "    df = pd.read_csv('df_review.csv')\n",
    "    df['fgi_image_url'] = df['fgi_images'].apply(extract_first_image_url)\n",
    "    df['cgi_image_url'] = df['cgi_images'].apply(extract_first_image_url)\n",
    "    tqdm.pandas(desc=\"Calculating Color Similarities\")\n",
    "    df['color_similarity'] = df.progress_apply(calculate_similarity, axis=1)\n",
    "\n",
    "    # Save the complete DataFrame to CSV\n",
    "    df.to_csv('df_review_color.csv', index=False)\n",
    "    print(\"Complete DataFrame saved to 'df_review_color.csv'.\")\n",
    "\n",
    "    # Drop the specified columns and save as a Stata DTA file\n",
    "    columns_to_drop = ['review_text', 'cgi_images', 'fgi_images', 'features']\n",
    "    df.drop(columns=columns_to_drop, errors='ignore').to_stata('df_review_color.dta', write_index=False)\n",
    "    print(\"Modified DataFrame saved to 'df_review_color.dta' without specified columns.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating Color Similarities: 100%|██████████| 9484/9484 [00:30<00:00, 314.68it/s]\n",
      "/var/folders/vz/_y_gw0w915v4z_x6ps3fjwwm0000gn/T/ipykernel_49918/1888943578.py:81: InvalidColumnName: \n",
      "Not all pandas column names were valid Stata variable names.\n",
      "The following replacements have been made:\n",
      "\n",
      "    Unnamed: 0   ->   Unnamed__0\n",
      "    color_similarity_intersect_scaled   ->   color_similarity_intersect_scale\n",
      "    color_similarity_bhattacharyya_scaled   ->   color_similarity_bhattacharyya_s\n",
      "\n",
      "If this is not what you expect, please make sure you have Stata-compliant\n",
      "column names in your DataFrame (strings only, max 32 characters, only\n",
      "alphanumerics and underscores, no Stata reserved words)\n",
      "\n",
      "  df.drop(columns=columns_to_drop, errors='ignore').to_stata('df_review_color.dta', write_index=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete DataFrame saved to 'df_review_color.csv'.\n",
      "Modified DataFrame saved to 'df_review_color.dta' without specified columns.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import cv2\n",
    "import numpy as np\n",
    "import requests\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "def load_image_from_url(url):\n",
    "    if not url:\n",
    "        return None\n",
    "    try:\n",
    "        resp = requests.get(url)\n",
    "        image = np.asarray(bytearray(resp.content), dtype=\"uint8\")\n",
    "        image = cv2.imdecode(image, cv2.IMREAD_COLOR)\n",
    "        return image\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Error loading image from {url}: {e}\")\n",
    "        return None\n",
    "\n",
    "def compute_normalized_histogram(image, bins=256):\n",
    "    if image is None:\n",
    "        return None\n",
    "    hist = []\n",
    "    for i in range(3):  # For each color channel\n",
    "        channel_hist = cv2.calcHist([image], [i], None, [bins], [0, 256])\n",
    "        cv2.normalize(channel_hist, channel_hist, norm_type=cv2.NORM_L2)\n",
    "        hist.append(channel_hist)\n",
    "    return hist\n",
    "\n",
    "def compare_histograms(hist1, hist2, method):\n",
    "    if hist1 is None or hist2 is None:\n",
    "        return None  # Return None if any histogram is missing\n",
    "    similarity = sum(cv2.compareHist(hist1[i], hist2[i], method) for i in range(3)) / 3\n",
    "    return similarity\n",
    "\n",
    "def extract_first_image_url(image_list_str):\n",
    "    if not image_list_str or image_list_str == '[]':\n",
    "        return None\n",
    "    try:\n",
    "        image_list = json.loads(image_list_str.replace(\"'\", '\"'))\n",
    "        if image_list:\n",
    "            return image_list[0]\n",
    "        else:\n",
    "            return None\n",
    "    except json.JSONDecodeError:\n",
    "        return None\n",
    "\n",
    "def calculate_similarities(row):\n",
    "    if row['cgi_image_url'] is None or row['fgi_image_url'] is None:\n",
    "        return pd.Series([None, None, None, None])  # Skip calculation if any URL is missing\n",
    "    image_cgi = load_image_from_url(row['cgi_image_url'])\n",
    "    image_fgi = load_image_from_url(row['fgi_image_url'])\n",
    "    hist_cgi = compute_normalized_histogram(image_cgi)\n",
    "    hist_fgi = compute_normalized_histogram(image_fgi)\n",
    "    corr = compare_histograms(hist_cgi, hist_fgi, cv2.HISTCMP_CORREL)\n",
    "    chi_square = compare_histograms(hist_cgi, hist_fgi, cv2.HISTCMP_CHISQR)\n",
    "    intersection = compare_histograms(hist_cgi, hist_fgi, cv2.HISTCMP_INTERSECT)\n",
    "    bhattacharyya = compare_histograms(hist_cgi, hist_fgi, cv2.HISTCMP_BHATTACHARYYA)\n",
    "    return pd.Series([corr, chi_square, intersection, bhattacharyya])\n",
    "\n",
    "def main():\n",
    "    df = pd.read_csv('df_review.csv')\n",
    "    df['fgi_image_url'] = df['fgi_images'].apply(extract_first_image_url)\n",
    "    df['cgi_image_url'] = df['cgi_images'].apply(extract_first_image_url)\n",
    "    \n",
    "    tqdm.pandas(desc=\"Calculating Color Similarities\")\n",
    "    df[['color_similarity_corr', 'color_similarity_chisqr', 'color_similarity_intersect', 'color_similarity_bhattacharyya']] = df.progress_apply(calculate_similarities, axis=1)\n",
    "\n",
    "    # Scale color similarity scores if necessary (e.g., multiply by 100)\n",
    "    df['color_similarity_corr_scaled'] = df['color_similarity_corr'] * 100\n",
    "    df['color_similarity_chisqr_scaled'] = df['color_similarity_chisqr'] * 100\n",
    "    df['color_similarity_intersect_scaled'] = df['color_similarity_intersect'] * 100\n",
    "    df['color_similarity_bhattacharyya_scaled'] = (1 - df['color_similarity_bhattacharyya']) * 100  # Inverted and scaled\n",
    "\n",
    "    # Save the complete DataFrame to CSV\n",
    "    df.to_csv('df_review_color.csv', index=False)\n",
    "    print(\"Complete DataFrame saved to 'df_review_color.csv'.\")\n",
    "\n",
    "    # Drop the specified columns and save as a Stata DTA file\n",
    "    columns_to_drop = ['review_text', 'cgi_images', 'fgi_images', 'features']\n",
    "    df.drop(columns=columns_to_drop, errors='ignore').to_stata('df_review_color.dta', write_index=False)\n",
    "    print(\"Modified DataFrame saved to 'df_review_color.dta' without specified columns.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The files have been successfully merged and saved to 'merged_file.csv'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vz/_y_gw0w915v4z_x6ps3fjwwm0000gn/T/ipykernel_49918/4241051771.py:29: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  csv2 = csv2.groupby('product_id', group_keys=False).apply(fill_below_first_non_na, columns=columns_to_merge)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the first CSV file\n",
    "csv1 = pd.read_csv('df_review_color.csv')\n",
    "\n",
    "# Load the second CSV file\n",
    "csv2 = pd.read_csv('df_review.csv')\n",
    "\n",
    "# Set 'Unnamed: 0' as the index for the first DataFrame\n",
    "csv1.set_index('Unnamed: 0', inplace=True)\n",
    "\n",
    "# Select the specific columns to merge from csv1\n",
    "columns_to_merge = ['color_similarity_corr_scaled', 'color_similarity_chisqr_scaled', \n",
    "                    'color_similarity_intersect_scaled', 'color_similarity_bhattacharyya_scaled']\n",
    "\n",
    "# Merge the specified columns into csv2 based on the 'Unnamed: 0' index\n",
    "csv2 = csv2.merge(csv1[columns_to_merge], how='left', left_index=True, right_index=True)\n",
    "\n",
    "# Function to fill values only for rows below the first occurrence of non-missing values\n",
    "def fill_below_first_non_na(df, columns):\n",
    "    for col in columns:\n",
    "        mask = df[col].notna()\n",
    "        first_non_na_idx = mask.idxmax() if mask.any() else None\n",
    "        if first_non_na_idx:\n",
    "            df.loc[first_non_na_idx+1:, col] = df.loc[first_non_na_idx, col]\n",
    "    return df\n",
    "\n",
    "# Apply the function to each group of 'product_id'\n",
    "csv2 = csv2.groupby('product_id', group_keys=False).apply(fill_below_first_non_na, columns=columns_to_merge)\n",
    "\n",
    "# Fill NaN values with 0\n",
    "csv2[columns_to_merge] = csv2[columns_to_merge].fillna(0)\n",
    "\n",
    "# Save the merged DataFrame to a new CSV file\n",
    "csv2.to_csv('df_review_color_merge.csv', index=False)\n",
    "\n",
    "print(\"The files have been successfully merged and saved to 'merged_file.csv'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No duplicates found.\n",
      "Data processing complete. Files saved.\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "input_file = 'df_review_color_merge'\n",
    "input_format = '.csv'\n",
    "\n",
    "# Function to load data\n",
    "def load_data(filename):\n",
    "    return pd.read_csv(filename)\n",
    "\n",
    "# Function to process data\n",
    "def process_data(df):\n",
    "    # Identify duplicates based on product_id and review_date\n",
    "    duplicates = df[df.duplicated(subset=['product_id', 'review_date'], keep=False)]\n",
    "\n",
    "    # Print duplicates if they exist\n",
    "    if not duplicates.empty:\n",
    "        print(\"Duplicates found:\")\n",
    "        print(duplicates)\n",
    "    else:\n",
    "        print(\"No duplicates found.\")\n",
    "\n",
    "    # Drop duplicates based on product_id and review_date\n",
    "    df = df.drop_duplicates(subset=['product_id', 'review_date'])\n",
    "    \n",
    "    # Convert review_date to the specified datetime format\n",
    "    df['datetime'] = pd.to_datetime(df['review_date']).dt.strftime('%d%b%Y %H:%M:%S')\n",
    "    \n",
    "    # Extract month and year from the datetime\n",
    "    df['mon'] = pd.to_datetime(df['review_date']).dt.month\n",
    "    df['year'] = pd.to_datetime(df['review_date']).dt.year\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Main function to run the process\n",
    "def main():\n",
    "    # Load data\n",
    "    df = load_data(input_file + input_format)\n",
    "    \n",
    "    # Process data\n",
    "    df_processed = process_data(df)\n",
    "    \n",
    "    # Save processed data\n",
    "    df_processed.to_csv(input_file + '_processed' + '.csv')\n",
    "    # df_processed.to_stata(input_file + '_processed' + '.dta', write_index=False)\n",
    "    \n",
    "    print(\"Data processing complete. Files saved.\")\n",
    "\n",
    "# Run the script\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
